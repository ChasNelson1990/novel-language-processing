{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Subject Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "# from collocater import collocater\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_db_url = \"http://corpus-db.org/api\"\n",
    "book = 'The Hound of The Baskervilles'\n",
    "book_id = 3070.0  # have to know the id at the moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcsh</th>\n",
       "      <th>creator</th>\n",
       "      <th>downloads</th>\n",
       "      <th>rights_url</th>\n",
       "      <th>authoryearofdeath</th>\n",
       "      <th>_repo</th>\n",
       "      <th>wp_subjects</th>\n",
       "      <th>gutenberg_issued</th>\n",
       "      <th>identifiers</th>\n",
       "      <th>formats</th>\n",
       "      <th>...</th>\n",
       "      <th>id</th>\n",
       "      <th>gutenberg_bookshelf</th>\n",
       "      <th>_version</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>wp_literary_genres</th>\n",
       "      <th>publisher</th>\n",
       "      <th>covers</th>\n",
       "      <th>description</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'Blessing and cursing -- Fiction', 'Holmes, S...</td>\n",
       "      <td>{'author': {'agent_name': 'Doyle, Arthur Conan...</td>\n",
       "      <td>348</td>\n",
       "      <td>http://creativecommons.org/about/pdm</td>\n",
       "      <td>1930</td>\n",
       "      <td>The-Hound-of-the-Baskervilles_3070</td>\n",
       "      <td>['Gothic_novels', '1902_novels', 'Dartmoor', '...</td>\n",
       "      <td>2002-02-01</td>\n",
       "      <td>{'gutenberg': '3070', 'wikidata': 'Q45192'}</td>\n",
       "      <td>{'text/plain; charset=us-ascii': 'http://www.g...</td>\n",
       "      <td>...</td>\n",
       "      <td>3070.0</td>\n",
       "      <td>Bestsellers, American, 1895-1923</td>\n",
       "      <td>0.2.0</td>\n",
       "      <td>The Hound of the Baskervilles</td>\n",
       "      <td>Text</td>\n",
       "      <td>['Detective_fiction']</td>\n",
       "      <td>Project Gutenberg</td>\n",
       "      <td>[{'cover_type': 'generated', 'image_path': 'co...</td>\n",
       "      <td>The Hound of the Baskervilles is the third of ...</td>\n",
       "      <td>/run/media/jon/SAMSUNG/gitenberg/The-Hound-of-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                lcsh  \\\n",
       "0  {'Blessing and cursing -- Fiction', 'Holmes, S...   \n",
       "\n",
       "                                             creator downloads  \\\n",
       "0  {'author': {'agent_name': 'Doyle, Arthur Conan...       348   \n",
       "\n",
       "                             rights_url authoryearofdeath  \\\n",
       "0  http://creativecommons.org/about/pdm              1930   \n",
       "\n",
       "                                _repo  \\\n",
       "0  The-Hound-of-the-Baskervilles_3070   \n",
       "\n",
       "                                         wp_subjects gutenberg_issued  \\\n",
       "0  ['Gothic_novels', '1902_novels', 'Dartmoor', '...       2002-02-01   \n",
       "\n",
       "                                   identifiers  \\\n",
       "0  {'gutenberg': '3070', 'wikidata': 'Q45192'}   \n",
       "\n",
       "                                             formats  ...      id  \\\n",
       "0  {'text/plain; charset=us-ascii': 'http://www.g...  ...  3070.0   \n",
       "\n",
       "                gutenberg_bookshelf _version                          title  \\\n",
       "0  Bestsellers, American, 1895-1923    0.2.0  The Hound of the Baskervilles   \n",
       "\n",
       "   type     wp_literary_genres          publisher  \\\n",
       "0  Text  ['Detective_fiction']  Project Gutenberg   \n",
       "\n",
       "                                              covers  \\\n",
       "0  [{'cover_type': 'generated', 'image_path': 'co...   \n",
       "\n",
       "                                         description  \\\n",
       "0  The Hound of the Baskervilles is the third of ...   \n",
       "\n",
       "                                            filename  \n",
       "0  /run/media/jon/SAMSUNG/gitenberg/The-Hound-of-...  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata = pd.DataFrame(json.loads(requests.get(corpus_db_url + f\"/id/{book_id}\").text), index=[0])\n",
    "metadata = metadata.replace('', np.nan).dropna(axis=1)\n",
    "\n",
    "display(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Full Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book is 318546 characters long.\n"
     ]
    }
   ],
   "source": [
    "corpus = json.loads(requests.get(corpus_db_url + f\"/id/{book_id}/fulltext\").text)\n",
    "\n",
    "print('Book is {0} characters long.'.format(len(corpus[0]['text'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load into SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " The Hound of the Baskervilles by Sir Arthur Conan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !python -m spacy download en_core_web_lg  # note this doesn't really work properly with pipenvs\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# collie = collocater.Collocater.loader()\n",
    "# nlp.add_pipe(collie)\n",
    "\n",
    "doc_string = re.sub(' +', ' ', corpus[0]['text'].replace('\\r', ' ').replace('\\n', ' ').replace(\"\\'\", \"'\"))  # remove weird characters and extra whitespace\n",
    "doc = nlp(doc_string)  \n",
    "\n",
    "display(doc[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of SpaCy properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cats',\n",
       " 'char_span',\n",
       " 'count_by',\n",
       " 'doc',\n",
       " 'ents',\n",
       " 'extend_tensor',\n",
       " 'from_array',\n",
       " 'from_bytes',\n",
       " 'from_disk',\n",
       " 'get_extension',\n",
       " 'get_lca_matrix',\n",
       " 'has_extension',\n",
       " 'has_vector',\n",
       " 'is_nered',\n",
       " 'is_parsed',\n",
       " 'is_sentenced',\n",
       " 'is_tagged',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'mem',\n",
       " 'merge',\n",
       " 'noun_chunks',\n",
       " 'noun_chunks_iterator',\n",
       " 'print_tree',\n",
       " 'remove_extension',\n",
       " 'retokenize',\n",
       " 'sentiment',\n",
       " 'sents',\n",
       " 'set_extension',\n",
       " 'similarity',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'to_array',\n",
       " 'to_bytes',\n",
       " 'to_disk',\n",
       " 'to_json',\n",
       " 'to_utf8_array',\n",
       " 'user_data',\n",
       " 'user_hooks',\n",
       " 'user_span_hooks',\n",
       " 'user_token_hooks',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display([prop for prop in dir(doc) if not prop.startswith('_')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Number of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words is 70781.\n"
     ]
    }
   ],
   "source": [
    "print('Total number of words is {0}.'.format(len(doc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Words Per Chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chapters(doc):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    doc (spacy.Doc): list of sentences representing a book\n",
    "\n",
    "    Returns:\n",
    "    A list of integers representing the positions of chapters as a word number\n",
    "    \"\"\"\n",
    "    \n",
    "    words = [t.text for t in doc]\n",
    "\n",
    "    chapter_word_idx = [] #represents location of chapters in book\n",
    "    chapter_word_idx.append(0)\n",
    "    for i,w in enumerate(words):\n",
    "        if w == \"Chapter\":\n",
    "            chapter_word_idx.append(i)\n",
    "    chapter_word_idx.append(len(words))\n",
    "        \n",
    "    return np.array(chapter_word_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2a9869e3404f7e96e11d6e4428e818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chapter_word_idx = split_into_chapters(doc)  # list of chapters locations in words\n",
    "ignore = 16  # ignore the first 16 for tHotB as they're the prelim\n",
    "chapter_word_idx = chapter_word_idx[ignore:]\n",
    "# display(chapter_word_idx)\n",
    "\n",
    "chapters = np.arange(1,len(chapter_word_idx))\n",
    "chapter_word_count = chapter_word_idx[1:] - chapter_word_idx[:-1]\n",
    "# display(chapters, chapter_word_count)\n",
    "\n",
    "plt.figure()\n",
    "sns.barplot(x=chapters, y=chapter_word_count)\n",
    "plt.ylabel('Word Count')\n",
    "plt.xlabel('Chapter')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique words (vocabulary) is 5627.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8e37c339204385a5ff66f74b952408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [w.text.lower() for w in doc]\n",
    "\n",
    "print('Total number of unique words (vocabulary) is {0}.'.format(len(set(words))))\n",
    "\n",
    "chapter_vocab = np.array([len(set(words[chapter_word_idx[i]:chapter_word_idx[i+1]])) for i in np.arange(len(chapters))])\n",
    "\n",
    "plt.figure()\n",
    "sns.barplot(x=chapters, y=100*chapter_vocab/chapter_word_count)\n",
    "plt.ylabel('Unique Word Count/%')\n",
    "plt.ylim(0,100)\n",
    "plt.xlabel('Chapter')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Common Words of Different Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 20 most common nouns are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "word\n",
       "the moor         133\n",
       "Holmes           112\n",
       "Sir Henry        102\n",
       "Dr. Mortimer      63\n",
       "Stapleton         60\n",
       "Sir Charles       53\n",
       "-PRON- friend     49\n",
       "the man           49\n",
       "-PRON- hand       47\n",
       "London            44\n",
       "Barrymore         43\n",
       "-PRON- eye        38\n",
       "the baronet       38\n",
       "the matter        35\n",
       "-PRON- wife       35\n",
       "-PRON- face       33\n",
       "a man             31\n",
       "-PRON- mind       31\n",
       "the house         30\n",
       "the hound         29\n",
       "Name: count, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Common Nouns\n",
    "nouns = [w.lemma_ for w in doc.noun_chunks if (not w.root.is_stop)]  # this gets rid of common pronouns like 'i', 'he', 'she', etc.\n",
    "nouns = pd.DataFrame(nouns,columns=['word'])\n",
    "nouns = nouns.groupby('word')['word']\n",
    "nouns = nouns.describe()['count']\n",
    "nouns = nouns.sort_values(ascending=False)\n",
    "print(\"The 20 most common nouns are:\")\n",
    "display(nouns.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 20 most common adjectives are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "word\n",
       "good       71\n",
       "old        69\n",
       "great      60\n",
       "little     55\n",
       "long       49\n",
       "black      45\n",
       "dark       42\n",
       "dear       31\n",
       "small      29\n",
       "able       27\n",
       "clear      27\n",
       "young      26\n",
       "poor       26\n",
       "strange    25\n",
       "gray       22\n",
       "ready      22\n",
       "new        21\n",
       "sure       21\n",
       "low        21\n",
       "deep       20\n",
       "Name: count, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Common Adjectives\n",
    "adjectives = [(w.lemma_) for w in doc if (not (w.is_punct or w.is_space or w.is_stop) and w.pos_==\"ADJ\")]\n",
    "adjectives = pd.DataFrame(adjectives, columns=['word'])\n",
    "adjectives = adjectives.groupby('word')['word']\n",
    "adjectives = adjectives.describe()['count']\n",
    "adjectives = adjectives.sort_values(ascending=False)\n",
    "print(\"The 20 most common adjectives are:\")\n",
    "display(adjectives.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 20 most common verbs are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "word\n",
       "say       246\n",
       "come      189\n",
       "know      182\n",
       "think     124\n",
       "tell      117\n",
       "see       111\n",
       "find       97\n",
       "hear       88\n",
       "look       87\n",
       "go         85\n",
       "take       69\n",
       "ask        69\n",
       "leave      68\n",
       "run        57\n",
       "turn       57\n",
       "stand      57\n",
       "give       54\n",
       "lie        44\n",
       "pass       44\n",
       "follow     44\n",
       "Name: count, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "verbs = [(w.lemma_) for w in doc if (not (w.is_punct or w.is_space or w.is_stop) and w.pos_==\"VERB\")]\n",
    "verbs = pd.DataFrame(verbs, columns=['word'])\n",
    "verbs = verbs.groupby('word')['word']\n",
    "verbs = verbs.describe()['count']\n",
    "verbs = verbs.sort_values(ascending=False)\n",
    "print(\"The 20 most common verbs are:\")\n",
    "display(verbs.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The times mentioned are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "word\n",
       "the night             11\n",
       "this morning          10\n",
       "last night             9\n",
       "the morning            8\n",
       "evening                7\n",
       "night                  7\n",
       "a few minute           4\n",
       "that night             4\n",
       "an hour                3\n",
       "the evening            3\n",
       "half an hour           3\n",
       "morning                3\n",
       "ten o'clock            3\n",
       "five or ten minute     2\n",
       "next morning           2\n",
       "two hour               2\n",
       "one night 's           2\n",
       "every night            2\n",
       "every evening          2\n",
       "twenty - four hour     2\n",
       "Name: count, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Times\n",
    "# times = [(w.root.text) for w in doc.ents if w.label_ == 'TIME']  # good for showing that most action is at night\n",
    "times = [(w.lemma_) for w in doc.ents if w.label_ == 'TIME']  # shows hours mentioned, e.g. ten o'clock\n",
    "times = pd.DataFrame(times, columns=['word'])\n",
    "times = times.groupby('word')['word']\n",
    "times = times.describe()['count']\n",
    "times = times.sort_values(ascending=False)\n",
    "print(\"The times mentioned are:\")\n",
    "display(times.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The persons mentioned by name are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "word\n",
       "Holmes                 146\n",
       "Henry                  130\n",
       "Watson                 113\n",
       "Stapleton               93\n",
       "Mortimer                85\n",
       "Charles                 79\n",
       "Barrymore               70\n",
       "Sherlock Holmes         29\n",
       "Henry Baskerville       24\n",
       "Coombe Tracey           18\n",
       "Charles Baskerville     15\n",
       "Lyons                   11\n",
       "Selden                  11\n",
       "Laura Lyons             11\n",
       "Baskerville              9\n",
       "Devonshire               9\n",
       "Lestrade                 9\n",
       "Cartwright               8\n",
       "James Mortimer           5\n",
       "Grimpen Mire             5\n",
       "Name: count, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Persons\n",
    "persons = [(w.lemma_) for w in doc.ents if w.label_ == 'PERSON']\n",
    "persons = pd.DataFrame(persons, columns=['word'])\n",
    "persons = persons.groupby('word')['word']\n",
    "persons = persons.describe()['count']\n",
    "persons = persons.sort_values(ascending=False)\n",
    "print(\"The persons mentioned by name are:\")\n",
    "display(persons.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 20 most common verbs associated with 'Holmes' are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "word\n",
       "say       52\n",
       "be        23\n",
       "look       6\n",
       "ask        5\n",
       "have       5\n",
       "cry        4\n",
       "think      3\n",
       "shrug      3\n",
       "Holmes     3\n",
       "strike     3\n",
       "lean       2\n",
       "follow     2\n",
       "see        2\n",
       "do         2\n",
       "come       2\n",
       "save       2\n",
       "lay        2\n",
       "\"          2\n",
       "sit        2\n",
       "tell       2\n",
       "Name: count, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verbs associated with Holmes\n",
    "holmes_verbs = [(w.sent.root.lemma_) for w in doc if w.text.lower()==\"holmes\"]\n",
    "holmes_verbs = pd.DataFrame(holmes_verbs, columns=['word'])\n",
    "holmes_verbs = holmes_verbs.groupby('word')['word']\n",
    "holmes_verbs = holmes_verbs.describe()['count']\n",
    "holmes_verbs = holmes_verbs.sort_values(ascending=False)\n",
    "print(\"The 20 most common verbs associated with 'Holmes' are:\")\n",
    "display(holmes_verbs.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocations\n",
    "\n",
    "Would like to use `collocater` here but there are some issues for me so have used nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/chas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sir Henry; Sir Charles; Dr. Mortimer; Sherlock Holmes; Coombe Tracey;\n",
      "Baskerville Hall; Merripit House; said Holmes; Dr. Watson; Grimpen\n",
      "Mire; Baker Street; Mr. Holmes; Henry Baskerville; Laura Lyons; Yew\n",
      "Alley; Mr. Sherlock; Northumberland Hotel; Mrs. Laura; Miss Stapleton;\n",
      "dear fellow\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "nltk_doc = nltk.Text(nltk.word_tokenize(doc_string))\n",
    "\n",
    "print(nltk_doc.collocations())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concordances and Dispersion Plots\n",
    "\n",
    "Of words from the book title, key characters and locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 69 matches:\n",
      "The Hound of the Baskervilles by Sir Arthur Co\n",
      "-- Fixing the Nets Chapter 14 -- The Hound of the Baskervilles Chapter 15 -- A \n",
      "rrative : -- `` Of the origin of the Hound of the Baskervilles there have been \n",
      "and there ran mute behind him such a hound of hell as God forbid should ever be\n",
      " great , black beast , shaped like a hound , yet larger than any hound that eve\n",
      "d like a hound , yet larger than any hound that ever mortal eye has rested upon\n",
      "ale , my sons , of the coming of the hound which is said to have plagued the fa\n",
      "ge creature or heard the baying of a hound . The latter question he put to me s\n",
      "ey were the footprints of a gigantic hound ! '' Chapter 3 The Problem I confess\n",
      "ark is material . '' `` The original hound was material enough to tug a man 's \n",
      " . `` Of course , I 've heard of the hound ever since I was in the nursery . It\n",
      "t ? '' `` The peasants say it is the Hound of the Baskervilles calling for its \n",
      "er ? '' `` You know the story of the hound ? '' `` I do not believe in such non\n",
      "heep-dog of the moor ? Or a spectral hound , black , silent , and monstrous ? W\n",
      "the baronet , `` it was the cry of a hound . '' My blood ran cold in my veins ,\n",
      "n . `` They say it is the cry of the Hound of the Baskervilles . '' He groaned \n",
      " was silent for a few moments . `` A hound it was , '' he said , at last , `` b\n",
      "nk yourself that it was the cry of a hound ? I am not a child . You need not fe\n",
      "ange bird . '' `` No , no , it was a hound . My God , can there be some truth i\n",
      "cle ! There was the footprint of the hound beside him as he lay . It all fits t\n",
      "ch resembled the distant baying of a hound . It is incredible , impossible , th\n",
      "ordinary laws of nature . A spectral hound which leaves material footmarks and \n",
      "ose that there were really some huge hound loose upon it ; that would go far to\n",
      " everything . But where could such a hound lie concealed , where did it get its\n",
      " other . And always , apart from the hound , there is the fact of the human age\n"
     ]
    }
   ],
   "source": [
    "nltk_doc.concordance('hound')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 93 matches:\n",
      "ankland , of Lafter Hall , and Mr. Stapleton , the naturalist , there are no ot\n",
      "ould send him back a new man . Mr. Stapleton , a mutual friend who was much con\n",
      "the residence of the naturalist -- Stapleton , if I remember right , was his na\n",
      "thing . There is this naturalist , Stapleton , and there is his sister , who is\n",
      "ur mutual friend , Mortimer . I am Stapleton , of Merripit House . '' `` Your n\n",
      "'' said I , `` for I knew that Mr. Stapleton was a naturalist . But how did you\n",
      "y kind . '' `` Excellent ! '' said Stapleton . `` You are perfectly right to be\n",
      "ghbours upon the moor . I accepted Stapleton 's invitation , and we turned toge\n",
      "em more fertile than the rest . '' Stapleton laughed . `` That is the great Gri\n",
      "ly , throbbing murmur once again . Stapleton looked at me with a curious expres\n",
      "cross our path , and in an instant Stapleton was rushing with extraordinary ene\n",
      "d not doubt that this was the Miss Stapleton of whom I had been told , since la\n",
      "t between brother and sister , for Stapleton was neutral tinted , with light ha\n",
      "see the beauties of the place . '' Stapleton had abandoned the chase and came b\n",
      "ords . `` I had a school , '' said Stapleton . `` It was in the north country .\n",
      "inite and distinct warning of Miss Stapleton , delivered with such intense earn\n",
      "e road I was astounded to see Miss Stapleton sitting upon a rock by the side of\n",
      "`` But I ca n't forget them , Miss Stapleton , '' said I . `` I am Sir Henry 's\n",
      ", please , be frank with me , Miss Stapleton , for ever since I have been here \n",
      "d ask you one more question , Miss Stapleton . If you meant no more than this w\n",
      "hould go over to sleep there , but Stapleton would not hear of it . The fact is\n",
      "enry was much interested and asked Stapleton more than once whether he did real\n",
      "that he was very much in earnest . Stapleton was guarded in his replies , but i\n",
      "enry made the acquaintance of Miss Stapleton . From the first moment that he sa\n",
      "h a match would be very welcome to Stapleton , and yet I have more than once ca\n"
     ]
    }
   ],
   "source": [
    "nltk_doc.concordance('Stapleton')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba8c6da6b9c4f7ea16c59493d794ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "nltk_doc.dispersion_plot(['hound','Hound','Baskervilles','Holmes','Watson','Henry','Stapleton'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381fba3ab3844787a34374dcfd65afc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "nltk_doc.dispersion_plot(['Hall', 'moor', 'Coombe', 'Devonshire', 'Grimpen', 'Merripit'])  # note that 'hall' and 'Hall' are different.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditonal Frequency Distributions\n",
    "\n",
    "Of key characters and locations over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f7b86203c948258f7f7c987101210a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "           (target, c)\n",
    "           for c in chapters\n",
    "           for w in nltk_doc[chapter_word_idx[c-1]:chapter_word_idx[c]]\n",
    "           for target in ['holmes', 'watson', 'henry', 'mortimer', 'stapleton', 'barrymore']\n",
    "           if w.lower().startswith(target))\n",
    "cfd.plot(cumulative=True)\n",
    "plt.xlabel('Chapter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a0bddb28bd432f97ab70f3cb9fe50c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "           (target, c)\n",
    "           for c in chapters\n",
    "           for w in nltk_doc[chapter_word_idx[c-1]:chapter_word_idx[c]]\n",
    "           for target in ['hall', 'moor', 'coombe', 'devonshire', 'grimpen', 'merripit']\n",
    "           if w.lower().startswith(target))\n",
    "cfd.plot(cumulative=True)\n",
    "plt.xlabel('Chapter')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "novel-language-processing",
   "language": "python",
   "name": "novel-language-processing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
